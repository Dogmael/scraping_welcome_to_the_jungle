{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_page_urls(base_url,max_page) :\n",
    "    urls = []\n",
    "    for i in range(1,max_page+1) :\n",
    "        urls.append(base_url+str(i))\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_companies_from_page(url) :\n",
    "    service = Service(executable_path=r'/usr/bin/chromedriver')\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(service = service, options = options)\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5) #Could be improve with some Selenium built in function\n",
    "\n",
    "    grid = driver.find_element(By.XPATH, '//*[@id=\"pages_jobs\"]/div[2]/div/ol')\n",
    "    offers = grid.find_elements(By.XPATH,\"//div/li/div\")\n",
    "\n",
    "    compagnies = []\n",
    "\n",
    "    for offer in offers :\n",
    "        html_doc = offer.get_attribute(\"innerHTML\")\n",
    "        soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "        compagnies.append(soup.find(\"span\").getText())\n",
    "\n",
    "    return compagnies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page =1scape sucessfuly\n",
      "next page\n",
      "page =2scape sucessfuly\n",
      "next page\n",
      "page =3scape sucessfuly\n",
      "next page\n",
      "page =4scape sucessfuly\n",
      "next page\n",
      "page =5scape sucessfuly\n",
      "next page\n",
      "page =6scape sucessfuly\n",
      "next page\n",
      "page =7scape sucessfuly\n",
      "next page\n",
      "page =8scape sucessfuly\n",
      "next page\n",
      "page =9scape sucessfuly\n",
      "next page\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.welcometothejungle.com/fr/jobs?refinementList%5Boffices.country_code%5D%5B%5D=FR&refinementList%5Bcontract_type%5D%5B%5D=APPRENTICESHIP&refinementList%5Bprofession.category.fr%5D%5B%5D=Tech&query=tech&page=\"\n",
    "max_page = 18 #Could be scrape aswell\n",
    "page_urls = generate_page_urls(base_url,max_page)\n",
    "\n",
    "compagnies = []\n",
    "for url in page_urls :\n",
    "    try :\n",
    "        compagnies.append(get_companies_from_page(url))\n",
    "        print(\"page \" + url[-2:] + \" scape sucessfuly\")\n",
    "    except :\n",
    "        pass\n",
    "        print(\"FAILED to scrape page\" + url[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compagnies = [item for sublist in compagnies for item in sublist] #flating list\n",
    "save_compagnies = compagnies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
